# SPDX-FileCopyrightText: 2021 Sebastian Garcia <sebastian.garcia@agents.fel.cvut.cz>
# SPDX-License-Identifier: GPL-2.0-only
import asyncio
import json
import ipaddress
import os
from queue import Queue
import threading
import time

from modules.arp.arp_scans_thread import ARPScansProcessor
from modules.arp.set_evidence import ARPSetEvidenceHelper
from slips_files.common.flow_classifier import FlowClassifier
from slips_files.common.parsers.config_parser import ConfigParser
from slips_files.common.slips_utils import utils

from slips_files.common.abstracts.iasync_module import IAsyncModule


class ARP(IAsyncModule):

    name = "ARP"
    description = "Detect ARP attacks"
    authors = ["Alya Gomaa"]

    async def init(self):
        self.channels = {
            "new_arp": self.new_arp_msg_handler,
            "tw_closed": self.tw_closed_msg_handler,
        }
        await self.db.subscribe(self.pubsub, self.channels.keys())
        self.set_evidence = ARPSetEvidenceHelper(self.db, self.conf, self.args)
        self.read_configuration()
        self.classifier = FlowClassifier()
        # this dict will categorize arp requests by profileid_twid
        self.cache_arp_requests = {}
        self.cache_arp_lock = threading.Lock()

        # Threshold to use to detect a port scan. How many arp minimum
        # are required?
        self.arp_scan_threshold = 5
        self.delete_arp_periodically = False
        self.arp_log_creation_time = 0
        self.period_before_deleting = 0

        if self.delete_zeek_files and not self.store_zeek_files_copy:
            self.delete_arp_periodically = True
            # first time arp.log is created
            self.arp_log_creation_time = time.time()
            # thats one hour in seconds
            self.period_before_deleting = 3600

        self.arp_scan_thread = utils.create_thread(
            self.wait_for_arp_scans, name="arp_scan_thread"
        )

        self.pending_arp_scan_evidence = Queue()
        self.alerted_once_arp_scan = False

        self.is_zeek_running: bool = self.is_running_zeek()

        # a way to tell the threads of this module to stop
        self.stop_signal = threading.Event()

    async def new_arp_msg_handler(self, msg):
        """Handler for new_arp channel messages"""
        try:
            msg = json.loads(msg["data"])
            profileid = msg["profileid"]
            twid = msg["twid"]
            # this is the actual arp flow
            flow = self.classifier.convert_to_flow_obj(msg["flow"])
            # PS: arp flows don't have uids by zeek. the uids received
            # are randomly generated by slips

            if self.check_if_gratutitous_arp(flow):
                # for MITM arp attack, the arp has to be gratuitous
                # and it has to be a reply operation, not a request.
                # A gratuitous ARP is always a reply. A MITM attack
                # happens when there is a reply without a request
                self.detect_mitm_arp_attack(twid, flow)
            else:
                # not gratuitous and request, may be an arp scan
                self.check_arp_scan(profileid, twid, flow)

            if "request" in flow.operation:
                self.check_dstip_outside_localnet(twid, flow)
            elif "reply" in flow.operation:
                # Unsolicited ARPs should be of type reply only, not request
                self.detect_unsolicited_arp(twid, flow)
        except Exception as e:
            self.print(f"Error processing new_arp message: {e}")

    async def tw_closed_msg_handler(self, msg):
        """Handler for tw_closed channel messages"""
        try:
            profileid_tw = msg["data"]
            # when a tw is closed, this means that it's too
            # old so we don't check for arp scan in this time
            # range anymore
            # this copy is made to avoid dictionary
            # changed size during iteration err
            cache_copy = self.cache_arp_requests.copy()
            for key in cache_copy:
                if profileid_tw in key:
                    with self.cache_arp_lock:
                        self.cache_arp_requests.pop(key)
                    # don't break, keep looking for more
                    # keys that belong to the same tw
        except Exception as e:
            self.print(f"Error processing tw_closed message: {e}")

    def read_configuration(self):
        conf = ConfigParser()
        self.home_network = conf.home_network_ranges
        self.delete_zeek_files = conf.delete_zeek_files()
        if self.delete_zeek_files:
            self.print(
                "Warning: Slips will delete Zeek log files after "
                "the analysis is done. and will delete arp.log every 1h. "
                "You can modify this by changing "
                "delete_zeek_files in the config file."
            )
        self.store_zeek_files_copy = conf.store_zeek_files_copy()

    def is_running_zeek(self) -> bool:
        return (
            self.db.get_input_type() == "pcap" or self.db.is_running_non_stop()
        )

    async def wait_for_arp_scans(self):
        """
        This thread waits for 10s then checks if more
        arp scans happened to reduce the number of evidence
        """
        loop = asyncio.get_event_loop()
        loop.set_exception_handler(self.handle_loop_exception)

        processor = await ARPScansProcessor.create(
            stop_signal=self.stop_signal,
            logger=self.logger,
            output_dir=self.output_dir,
            redis_port=self.redis_port,
            conf=self.conf,
            slips_args=self.args,
            main_pid=self.ppid,
            start_redis_server=False,
            pending_arp_scan_evidence=self.pending_arp_scan_evidence,
            cache_arp_requests=self.cache_arp_requests,
            cache_arp_lock=self.cache_arp_lock,
        )
        await processor.start()

    def check_arp_scan(self, profileid, twid, flow):
        """
        Check if the profile is doing an arp scan
        If IP X sends arp requests to 3 or more different
        IPs within 30 seconds, then this IP X is doing arp scan
        The key profileid_twid is used to group requests
        from the same saddr
        arp flows don't have uids, the uids received are
        randomly generated by slips
        """
        if (
            "request" not in flow.operation
            or "00:00:00:00:00:00" not in flow.dst_hw
        ):
            return False

        def get_uids():
            """
            get the uids causing this evidence
            """
            res = []
            for daddr, daddr_info in cached_requests.items():
                for uid in daddr_info["uids"]:
                    res.append(uid)
            return res

        # The Gratuitous arp is sent as a broadcast, as a way for a
        # node to announce or update its IP to MAC mapping
        # to the entire network. It shouldn't be marked as an arp scan
        # Don't detect arp scan from the GW router
        if self.db.get_gateway_ip() == flow.saddr:
            return False

        if flow.saddr == "0.0.0.0":
            return False

        daddr_info = {flow.daddr: {"uids": [flow.uid], "ts": flow.starttime}}
        with self.cache_arp_lock:
            try:
                # Get together all the arp requests to IPs in this TW
                cached_requests = self.cache_arp_requests[
                    f"{profileid}_{twid}"
                ]

                if flow.daddr in cached_requests:
                    print(f"@@@@@@@@@@@@@@@@ {flow}")
                    cached_requests[flow.daddr]["uids"].append(flow.uid)
                    cached_requests[flow.daddr]["ts"] = flow.starttime
                    self.cache_arp_requests[f"{profileid}_{twid}"] = (
                        cached_requests
                    )
                else:
                    cached_requests.update(daddr_info)
            except KeyError:
                # create the key for this profileid_twid if it doesn't exist
                self.cache_arp_requests[f"{profileid}_{twid}"] = daddr_info
                return True

        # the list of daddrs that are scanned by the current
        # profileid in the curr tw
        daddrs = list(cached_requests.keys())

        # The minimum amount of arp packets to send to be
        # considered as scan is 5
        if len(daddrs) >= self.arp_scan_threshold:
            # check if these requests happened within 30 secs
            # get the first and the last request of the 10
            first_daddr = daddrs[0]
            last_daddr = daddrs[-1]
            starttime = cached_requests[first_daddr]["ts"]
            endtime = cached_requests[last_daddr]["ts"]
            # todo do we need mac addresses?
            self.diff = utils.get_time_diff(starttime, endtime)

            # in seconds
            if self.diff <= 30.00:
                uids = get_uids()
                # we are sure this is an arp scan
                if not self.alerted_once_arp_scan:
                    self.alerted_once_arp_scan = True
                    self.set_evidence.arp_scan(
                        flow.starttime, profileid, twid, uids
                    )
                    # after we set evidence, clear the dict so we can detect if it
                    # does another scan
                    with self.cache_arp_lock:
                        try:
                            self.cache_arp_requests.pop(f"{profileid}_{twid}")
                        except KeyError:
                            # when a tw is closed, we clear all its' entries from the
                            # cache_arp_requests dict
                            # having keyerr is a result of closing a timewindow before
                            # setting an evidence
                            # ignore it
                            pass

                else:
                    # after alerting once, wait 10s to see
                    # if more evidence are coming
                    self.pending_arp_scan_evidence.put(
                        (flow.starttime, profileid, twid, uids)
                    )

                return True
        return False

    def check_dstip_outside_localnet(self, twid, flow):
        """Function to setEvidence when daddr is outside the local network"""

        if "0.0.0.0" in flow.saddr or "0.0.0.0" in flow.daddr:
            # this is the case of arp probe, not an
            # arp outside of local network, don't alert
            return False

        daddr_as_obj = ipaddress.IPv4Address(flow.daddr)
        if daddr_as_obj.is_multicast or daddr_as_obj.is_link_local:
            # The arp to ‘outside’ the network should
            # not detect multicast or link-local addresses.
            return False

        for network in self.home_network:
            if daddr_as_obj in network:
                # IP is in this local network, don't alert
                return False

        # to prevent arp alerts from one IP to itself
        first_octet = flow.saddr.split(".")[0]
        if not flow.daddr.startswith(first_octet):
            self.set_evidence.dstip_outside_localnet(flow, twid)
            return True

        return False

    def detect_unsolicited_arp(self, twid: str, flow):
        """
        Unsolicited arp replies are used to update the neighbours'
        arp caches but can also be used in arp spoofing
        """
        if (
            flow.dmac == "ff:ff:ff:ff:ff:ff"
            and flow.dst_hw == "ff:ff:ff:ff:ff:ff"
            and flow.smac != "00:00:00:00:00:00"
            and flow.src_hw != "00:00:00:00:00:00"
        ):
            self.set_evidence.unsolicited_arp(flow, twid)
            return True

    def detect_mitm_arp_attack(self, twid: str, flow):
        """
        Detects when a MAC with IP A, is trying to tell others that
        now that MAC is also for IP B (arp cache attack)
        """
        # Todo in rare cases, the vendor and IP of this mac is known AFTER
        #  returning from this function so detection is missed

        # to test this add these 2 flows to arp.log
        # {"ts":1636305825.755132,"operation":"reply",
        # "src_mac":"2e:a4:18:f8:3d:02", "dst_mac":"ff:ff:ff:ff:ff:ff",
        # "orig_h":"172.20.7.40","resp_h":"172.20.7.40",
        # "orig_hw":"2e:a4:18:f8:3d:02", "resp_hw":"00:00:00:00:00:00"}
        # {"ts":1636305825.755132,"operation":"reply",
        # "src_mac":"2e:a4:18:f8:3d:02", "dst_mac":"ff:ff:ff:ff:ff:ff",
        # "orig_h":"172.20.7.41","resp_h":"172.20.7.41",
        # "orig_hw":"2e:a4:18:f8:3d:02", "resp_hw":"00:00:00:00:00:00"}

        # todo will we get FPs when an ip changes?
        # todo what if the ip of the attacker came to us
        #  first and we stored it in the db?
        #  the original IP of this src mac is now the IP of the attacker?

        # get the original IP of the src mac from the database
        original_ip: str = self.db.get_ip_of_mac(flow.smac)
        if original_ip is None:
            return

        # original_IP is a serialized list
        original_ip: str = json.loads(original_ip)[0]
        original_ip = original_ip.replace("profile_", "")

        # is this saddr trying to tell everyone that this
        # it owns this flow.smac even though we know this
        # src_mac is associated
        # with another IP (original_IP)?
        if flow.saddr != original_ip:
            self.set_evidence.mitm_arp_attack(flow, twid, original_ip)
            return True

    def check_if_gratutitous_arp(self, flow):
        """
        Check if an ARP packet is gratuitous

        The Gratuitous arp is sent as a broadcast, as a way for a
        node to announce or update
        its IP to MAC mapping to the entire network.
        Gratuitous ARP shouldn't be marked as an arp scan
        Check https://www.practicalnetworking.net/series/arp/gratuitous-arp/


        Gratuitous ARP can be used for (1) Updating ARP Mapping,
        (2) Announcing a Node’s Existence,
        (3) Redundancy, (4) MITM. Which is similar to an
        'unrequested' load balancing
         The saddr and daddr are the ones being avertised.
         The supposed purpose of the Gratuitous ARP
        """
        # It should be a reply
        # The dst_mac should be ff:ff:ff:ff:ff:ff or 00:00:00:00:00:00
        return "reply" in flow.operation and flow.dst_hw in [
            "ff:ff:ff:ff:ff:ff",
            "00:00:00:00:00:00",
        ]

    def clear_arp_logfile(self):
        if not self.delete_arp_periodically:
            return

        if not self.is_zeek_running:
            # we only clear arp.log if it's growing, aka zeek is running in
            # real time and generating logs constantly. like
            # interfaces/pcaps and growing zeek dirs
            return

        if (
            time.time()
            >= self.arp_log_creation_time + self.period_before_deleting
        ):
            arp_log_file_path = os.path.join(
                self.db.get_output_dir(), "zeek_files/arp.log"
            )
            open(arp_log_file_path, "w").close()
            # update ts of the new arp.log
            self.arp_log_creation_time = time.time()

    async def pre_main(self):
        """runs once before the main() is executed in a loop"""
        utils.drop_root_privs_permanently()
        await utils.start_thread(self.arp_scan_thread, self.db)

    async def main(self):
        """Main loop function"""
        self.clear_arp_logfile()
        # The main loop is now handled by the base class through message dispatching
        # Individual message handlers are called automatically
        # when messages arrive
