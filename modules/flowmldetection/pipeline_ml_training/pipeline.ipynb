{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e9265f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dataset_wrapper import find_and_load_datasets\n",
    "from classifier_wrapper import SKLearnClassifierWrapper\n",
    "from preprocessing_wrapper import PreprocessingWrapper\n",
    "from logger import Logger\n",
    "from features import FeatureExtraction\n",
    "\n",
    "import subprocess\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "# other models, preprocessing, scalers etc.\n",
    "import warnings\n",
    "\n",
    "# other models, preprocessing, scalers etc.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning,module=\"sklearn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a20e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths, constants\n",
    "root = \"../../../dataset-private/\" # path to the datasets \n",
    "validation_split=0.1\n",
    "experiment_name = \"test_longer_commands\"\n",
    "seed = 1111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a11bd2b",
   "metadata": {},
   "source": [
    "## Loading, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fa3055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found datasets: ['001-zeek-scenario-malicious', '003-zeek-scenario-malicious', '008-zeek-mixed', '009-zeek-malicious', '010-zeek-mixed', '011-zeek-mixed', '012-zeek-mixed', '013-zeek-mixed', '014-zeek-malicious', '015-zeek-malicious', '016-zeek-malicious', '017-zeek-malicious', '018-zeek-malicious', '020-zeek-malicious', '021-zeek-malicious', '022-zeek-malicious', '023-zeek-malicious', '024-zeek-malicious', '025-zeek-malicious', '026-zeek-malicious', '027-zeek-malicious', '028-zeek-malicious', '029-zeek-malicious', '030-zeek-malicious', '031-zeek-malicious', '032-zeek-malicious', '033-zeek-malicious', '034-zeek-malicious', '035-zeek-malicious', '036-zeek-malicious', '037-zeek-mixed']\n",
      "001-zeek-scenario-malicious: 253 samples\n",
      "003-zeek-scenario-malicious: 361 samples\n",
      "008-zeek-mixed: 5603 samples\n",
      "009-zeek-malicious: 79401 samples\n",
      "010-zeek-mixed: 5310 samples\n",
      "011-zeek-mixed: 8722 samples\n",
      "012-zeek-mixed: 3810 samples\n",
      "013-zeek-mixed: 26241 samples\n",
      "014-zeek-malicious: 26738 samples\n",
      "015-zeek-malicious: 197722 samples\n",
      "016-zeek-malicious: 34633 samples\n",
      "017-zeek-malicious: 39381 samples\n",
      "018-zeek-malicious: 33986 samples\n",
      "020-zeek-malicious: 35159 samples\n",
      "021-zeek-malicious: 33878 samples\n",
      "022-zeek-malicious: 5533 samples\n",
      "023-zeek-malicious: 5460 samples\n",
      "024-zeek-malicious: 5533 samples\n",
      "025-zeek-malicious: 5341 samples\n",
      "026-zeek-malicious: 5355 samples\n",
      "027-zeek-malicious: 2217 samples\n",
      "028-zeek-malicious: 2136 samples\n",
      "029-zeek-malicious: 2447 samples\n",
      "030-zeek-malicious: 2238 samples\n",
      "031-zeek-malicious: 2196 samples\n",
      "032-zeek-malicious: 26738 samples\n",
      "033-zeek-malicious: 11611 samples\n",
      "034-zeek-malicious: 11679 samples\n",
      "035-zeek-malicious: 11853 samples\n",
      "036-zeek-malicious: 11797 samples\n",
      "037-zeek-mixed: 5850 samples\n"
     ]
    }
   ],
   "source": [
    "loaders = find_and_load_datasets(root) #helper function from dataset_loader.py\n",
    "\n",
    "found_datasets=list(loaders.keys())\n",
    "print(\"Found datasets:\", found_datasets)\n",
    "\n",
    "\"\"\" results = sample_n_from_each_dataset(loaders,n=3)\n",
    "for ds_name, info in results.items():\n",
    "    print(f\"Dataset: {ds_name}  (file used: {info['file']})  samples: {len(info['samples'])}\")\n",
    "    display(info['df']) \"\"\"\n",
    "\n",
    "#print datasets\n",
    "for name, loader in loaders.items():\n",
    "    print(f\"{name}: {len(loader)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b58f1",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "466cc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature processing\n",
    "feature_extraction = FeatureExtraction()\n",
    "\n",
    "#preprocessing\n",
    "scaler = StandardScaler() \n",
    "preprocessor = PreprocessingWrapper(experiment_name=experiment_name)\n",
    "preprocessor.add_step(\"scaler\", scaler)\n",
    "pca = IncrementalPCA(n_components=7)\n",
    "preprocessor.add_step(\"pca\", pca)\n",
    "\n",
    "#other steps here? add your own!\n",
    "\n",
    "#classifier\n",
    "model = SGDClassifier(loss='hinge', penalty='l2',random_state=seed) \n",
    "classifier = SKLearnClassifierWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adae8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of commands to run\n",
    "# each command is either \"train\" or \"test\"\n",
    "# dataset_prefix is 3 numbers always - which dataset to use (008, 009, 010, ...)\n",
    "# validation = use validation portion when training\n",
    "commands = [\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"008\"},#, \"validation\": True},\n",
    "    {\"command\": \"test\", \"dataset_prefix\": \"008\"},\n",
    "    {\"command\": \"test\", \"dataset_prefix\": \"009\"},\n",
    "    {\"command\": \"test\", \"dataset_prefix\": \"015\"},\n",
    "    \n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"009\", \"validation\": True}, # evaluation\n",
    "    # TODO: training error only from training part?\n",
    "    {\"command\": \"test\", \"dataset_prefix\": \"008\"},\n",
    "    {\"command\": \"test\", \"dataset_prefix\": \"009\"},\n",
    "    {\"command\": \"test\", \"dataset_prefix\": \"017\"}, \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11037f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset 008-zeek-mixed\n",
      "Processing batch 0\n",
      "Testing on dataset 008-zeek-mixed\n",
      "Processing batch 0\n",
      "Testing on dataset 009-zeek-malicious\n",
      "Processing batch 0\n",
      "Processing batch 50\n",
      "Testing on dataset 015-zeek-malicious\n",
      "Processing batch 0\n",
      "Processing batch 50\n",
      "Processing batch 100\n",
      "Processing batch 150\n",
      "Training on dataset 009-zeek-malicious\n",
      "Processing batch 0\n",
      "Processing batch 50\n",
      "Processing batch 100\n",
      "Processing batch 150\n",
      "Testing on dataset 008-zeek-mixed\n",
      "Processing batch 0\n",
      "Testing on dataset 009-zeek-malicious\n",
      "Processing batch 0\n",
      "Processing batch 50\n",
      "Testing on dataset 017-zeek-malicious\n",
      "Processing batch 0\n"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "    # call batch from dataset\n",
    "    # process features\n",
    "    # preprocessing (scaling)\n",
    "    # train on model with validation, logger for metrics!\n",
    "    # save model after the whole dataset is done\n",
    "    # reporting, metrics, plots, etc.\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Ensure log experiment folder exists\n",
    "experiment_folder = os.path.join(\".\", \"logs\", experiment_name)\n",
    "if os.path.exists(experiment_folder):\n",
    "    if os.path.isdir(experiment_folder):\n",
    "        shutil.rmtree(experiment_folder)\n",
    "    else:\n",
    "        os.remove(experiment_folder)\n",
    "os.makedirs(experiment_folder, exist_ok=False)\n",
    "\n",
    "# Save config to configs.txt in the experiment folder (for reproducibility)\n",
    "config_path = os.path.join(experiment_folder, \"configs.txt\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"seed\": seed,\n",
    "        \"validation_split\": validation_split,\n",
    "        \"commands\": commands,\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"root\": root\n",
    "    }, f, indent=4)\n",
    "\n",
    "# check if the model is fitted (now just to know if we can test from the start or need to train first)\n",
    "try:\n",
    "    dummy_input = np.zeros((1, model.n_features_in_))\n",
    "    classifier.predict(dummy_input)\n",
    "    is_fitted = True\n",
    "except Exception:\n",
    "    print(\"Model is not fitted.\")\n",
    "    is_fitted = False\n",
    "\n",
    "\n",
    "# main loop doing commands one by one, and storing logs\n",
    "for command_idx,command_dict in enumerate(commands):\n",
    "\n",
    "    #find the dataset we wanted to use\n",
    "    ds = command_dict[\"dataset_prefix\"]\n",
    "    try:    \n",
    "        selected_dataset = next(name for name in found_datasets if ds in name)\n",
    "        loader = loaders[selected_dataset]\n",
    "    except StopIteration:\n",
    "        print(f\"No dataset found for {ds}, skipping\")\n",
    "        if command_idx == 0 and not is_fitted:\n",
    "            print(\"No dataset for the first training command, exiting\")\n",
    "            exit(1)\n",
    "        continue\n",
    "\n",
    "    # based on the command specified, do the action\n",
    "    command = command_dict[\"command\"]\n",
    "    if command == \"train\":\n",
    "        loader.reset_epoch(batch_size=500)\n",
    "        path_to_logfile = f\"{command_idx}_train_{ds}\"\n",
    "        logger = Logger(experiment_name = f\"{experiment_name}\",path_to_logfile = path_to_logfile, overwrite=True)\n",
    "        print(f\"Training on dataset {selected_dataset}\")\n",
    "        do_validation = command_dict.get(\"validation\", False)\n",
    "\n",
    "        for i in range(loader.batches()):\n",
    "            if i %50 == 0:\n",
    "                print(f\"Processing batch {i}\")\n",
    "            batch = loader.next_batch()\n",
    "            X, y = feature_extraction.process_batch(batch)\n",
    "            sum_labeled_flows = len(y)\n",
    "\n",
    "            if do_validation:\n",
    "                X_train, X_val, y_gt_train, y_gt_val = train_test_split(X, y, test_size=validation_split, random_state=seed)\n",
    "\n",
    "                #preprocessor\n",
    "                preprocessor.partial_fit(X_train)\n",
    "                X_train_processed = preprocessor.transform(X_train)\n",
    "\n",
    "                #classif\n",
    "                classifier.partial_fit(X_train_processed, y_gt_train)\n",
    "                y_pred_train = classifier.predict(X_train_processed)\n",
    "\n",
    "                # predict on validation set\n",
    "                X_val_processed = preprocessor.transform(X_val)\n",
    "                y_pred_val = classifier.predict(X_val_processed)\n",
    "                logger.save_training_results(\n",
    "                    y_pred_train, y_gt_train, y_pred_val, y_gt_val, sum_labeled_flows\n",
    "                )\n",
    "            else:\n",
    "                preprocessor.partial_fit(X)\n",
    "                X_processed = preprocessor.transform(X)\n",
    "                classifier.partial_fit(X_processed, y)\n",
    "                y_pred_train = classifier.predict(X_processed)\n",
    "                logger.save_training_results(\n",
    "                    y_pred_train, y, None, None, sum_labeled_flows # None is for validation\n",
    "                )\n",
    "\n",
    "        # After training, plot the training performance using the external script, not here!\n",
    "\n",
    "\n",
    "    elif command == \"test\":\n",
    "        path_to_logfile = f\"{command_idx}_test_{ds}\"\n",
    "        logger = Logger(experiment_name = f\"{experiment_name}\",path_to_logfile = path_to_logfile, overwrite=True)\n",
    "        loader.reset_epoch(batch_size=1_000)\n",
    "        print(f\"Testing on dataset {selected_dataset}\")\n",
    "        for i in range(loader.batches()):\n",
    "            batch = loader.next_batch()\n",
    "            if i %50 == 0:\n",
    "                print(f\"Processing batch {i}\")\n",
    "            X, y = feature_extraction.process_batch(batch)\n",
    "            if X.shape[0] == 0:\n",
    "                continue\n",
    "            X_processed = preprocessor.transform(X)\n",
    "            y_pred = classifier.predict(X_processed)\n",
    "            logger.save_test_results(y, y_pred)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(f\"Unknown command {command}, skipping\")\n",
    "        continue\n",
    "\n",
    "#save model, preprocessor steps and add config to the configs.txt\n",
    "models_path= f\"./models/{experiment_name}\"\n",
    "# ensure models directory is fresh (delete if already created)\n",
    "models_path = f\"./models/{experiment_name}\"\n",
    "if os.path.exists(models_path):\n",
    "    if os.path.isdir(models_path):\n",
    "        shutil.rmtree(models_path)\n",
    "    else:\n",
    "        os.remove(models_path)\n",
    "os.makedirs(models_path, exist_ok=False)\n",
    "classifier.save_classifier(path = models_path ,name = \"model_lin_SGD.bin\")\n",
    "preprocessor.save() #saves in models/<experiment_name>/preprocessing/<step_name>\n",
    "\n",
    "#  append feature names from the first preprocessing step and model parameters to configs.txt\n",
    "# get feature names from the first step in the preprocessor\n",
    "first_preprocessor_step = preprocessor.steps[0][1]\n",
    "if hasattr(first_preprocessor_step, 'get_feature_names_out'):\n",
    "    feature_names = first_preprocessor_step.get_feature_names_out()\n",
    "elif hasattr(first_preprocessor_step, 'feature_names_in_'):\n",
    "    feature_names = first_preprocessor_step.feature_names_in_\n",
    "else:\n",
    "    feature_names = None\n",
    "\n",
    "# Get model parameters\n",
    "model_params = model.get_params()\n",
    "model_info = {\n",
    "    \"class\": type(model).__name__,\n",
    "    \"loss\": getattr(model, \"loss\", None),\n",
    "    \"params\": model_params\n",
    "}\n",
    "\n",
    "# Append to configs.txt\n",
    "with open(config_path, \"a\") as f:\n",
    "    f.write(\"\\n\\n# Feature names from first preprocessing step:\\n\")\n",
    "    if feature_names is not None:\n",
    "        f.write(json.dumps({\"feature_names\": list(feature_names)}, indent=4))\n",
    "    else:\n",
    "        f.write(\"# Feature names not available\\n\")\n",
    "    f.write(\"\\n\\n# Model information:\\n\")\n",
    "    f.write(json.dumps(model_info, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "379b121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading logfile: logs/test_longer_commands/0_train_008\n",
      "[INFO] Accumulating batch and cumulative metrics...\n",
      "Training plots will be saved to: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/training/0_train_008/training\n",
      "[INFO] Not enough batches for last-20 (training), skipping.\n",
      "\n",
      "=== TRAINING Multi-class (Aggregated) ===\n",
      "Benign-Malicious Acc: 0.6934\n",
      "Malware F1:           0.8153\n",
      "Malware FPR:          0.9341\n",
      "Malware FNR:          0.0972\n",
      "Macro F1:             0.4562\n",
      "Precision:             0.7433\n",
      "Recall:                0.9028\n",
      "\n",
      "=== Per-class metrics (Aggregated) - TRAINING ===\n",
      "Class                 TP       TN       FP       FN      Acc     Prec      Rec       F1\n",
      "Benign                92     3779      407     1305   0.6934   0.1844   0.0659   0.0970\n",
      "Malicious           3779       92     1305      407   0.6934   0.7433   0.9028   0.8153\n",
      "\n",
      "Summary for Experiment 0_train_008:\n",
      "Total batches processed: 12\n",
      "Data type: Training only\n",
      "[INFO] Output folder: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/testing/1_test_008\n",
      "[INFO] Reading testing logfile: logs/test_longer_commands/1_test_008\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.7500\n",
      "Malware F1:           0.8571\n",
      "Malware FPR:          1.0000\n",
      "Malware FNR:          0.0000\n",
      "Macro F1:             0.4286\n",
      "Precision:            0.7500\n",
      "Recall:               1.0000\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious           4187        0     1396        0   0.7500   1.0000   0.8571\n",
      "Benign                 0     4187        0     1396   0.0000   0.0000   0.0000\n",
      "\n",
      "Summary for Experiment 1_test_008:\n",
      "Total test lines processed: 6\n",
      "[INFO] Output folder: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/testing/2_test_009\n",
      "[INFO] Reading testing logfile: logs/test_longer_commands/2_test_009\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.8059\n",
      "Malware F1:           0.8925\n",
      "Malware FPR:          1.0000\n",
      "Malware FNR:          0.0000\n",
      "Macro F1:             0.4463\n",
      "Precision:            0.8059\n",
      "Recall:               1.0000\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious          52489        0    12640        0   0.8059   1.0000   0.8925\n",
      "Benign                 0    52489        0    12640   0.0000   0.0000   0.0000\n",
      "\n",
      "Summary for Experiment 2_test_009:\n",
      "Total test lines processed: 80\n",
      "[INFO] Output folder: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/testing/3_test_015\n",
      "[INFO] Reading testing logfile: logs/test_longer_commands/3_test_015\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.8106\n",
      "Malware F1:           0.8954\n",
      "Malware FPR:          1.0000\n",
      "Malware FNR:          0.0000\n",
      "Macro F1:             0.4477\n",
      "Precision:            0.8106\n",
      "Recall:               1.0000\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious         132368        0    30927        0   0.8106   1.0000   0.8954\n",
      "Benign                 0   132368        0    30927   0.0000   0.0000   0.0000\n",
      "\n",
      "Summary for Experiment 3_test_015:\n",
      "Total test lines processed: 198\n",
      "[INFO] Reading logfile: logs/test_longer_commands/4_train_009\n",
      "[INFO] Accumulating batch and cumulative metrics...\n",
      "Validation plots will be saved to: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/training/4_train_009/validation\n",
      "Training plots will be saved to: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/training/4_train_009/training\n",
      "Comparison plots will be saved to: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/training/4_train_009/comparison\n",
      "\n",
      "=== VALIDATION Multi-class (Aggregated) ===\n",
      "Benign-Malicious Acc: 0.7176\n",
      "Malware F1:           0.8294\n",
      "Malware FPR:          0.8335\n",
      "Malware FNR:          0.1542\n",
      "Macro F1:             0.5057\n",
      "Precision:             0.8135\n",
      "Recall:                0.8458\n",
      "\n",
      "=== TRAINING Multi-class (Aggregated) ===\n",
      "Benign-Malicious Acc: 0.7184\n",
      "Malware F1:           0.8300\n",
      "Malware FPR:          0.8351\n",
      "Malware FNR:          0.1543\n",
      "Macro F1:             0.5048\n",
      "Precision:             0.8150\n",
      "Recall:                0.8457\n",
      "\n",
      "=== Per-class metrics (Aggregated) - VALIDATION ===\n",
      "Class                 TP       TN       FP       FN      Acc     Prec      Rec       F1\n",
      "Benign               207     4520      824     1036   0.7176   0.2008   0.1665   0.1821\n",
      "Malicious           4520      207     1036      824   0.7176   0.8135   0.8458   0.8294\n",
      "\n",
      "=== Per-class metrics (Aggregated) - TRAINING ===\n",
      "Class                 TP       TN       FP       FN      Acc     Prec      Rec       F1\n",
      "Benign              1805    40253     7344     9140   0.7184   0.1973   0.1649   0.1797\n",
      "Malicious          40253     1805     9140     7344   0.7184   0.8150   0.8457   0.8300\n",
      "\n",
      "Summary for Experiment 4_train_009:\n",
      "Total batches processed: 159\n",
      "Data type: Training/Validation split\n",
      "[INFO] Output folder: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/testing/5_test_008\n",
      "[INFO] Reading testing logfile: logs/test_longer_commands/5_test_008\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.7500\n",
      "Malware F1:           0.8571\n",
      "Malware FPR:          1.0000\n",
      "Malware FNR:          0.0000\n",
      "Macro F1:             0.4286\n",
      "Precision:            0.7500\n",
      "Recall:               1.0000\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious           4187        0     1396        0   0.7500   1.0000   0.8571\n",
      "Benign                 0     4187        0     1396   0.0000   0.0000   0.0000\n",
      "\n",
      "Summary for Experiment 5_test_008:\n",
      "Total test lines processed: 6\n",
      "[INFO] Output folder: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/testing/6_test_009\n",
      "[INFO] Reading testing logfile: logs/test_longer_commands/6_test_009\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.8059\n",
      "Malware F1:           0.8925\n",
      "Malware FPR:          1.0000\n",
      "Malware FNR:          0.0000\n",
      "Macro F1:             0.4463\n",
      "Precision:            0.8059\n",
      "Recall:               1.0000\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious          52489        0    12640        0   0.8059   1.0000   0.8925\n",
      "Benign                 0    52489        0    12640   0.0000   0.0000   0.0000\n",
      "\n",
      "Summary for Experiment 6_test_009:\n",
      "Total test lines processed: 80\n",
      "[INFO] Output folder: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_longer_commands/testing/7_test_017\n",
      "[INFO] Reading testing logfile: logs/test_longer_commands/7_test_017\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.0229\n",
      "Malware F1:           0.0448\n",
      "Malware FPR:          1.0000\n",
      "Malware FNR:          0.0000\n",
      "Macro F1:             0.0224\n",
      "Precision:            0.0229\n",
      "Recall:               1.0000\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious             47        0     2002        0   0.0229   1.0000   0.0448\n",
      "Benign                 0       47        0     2002   0.0000   0.0000   0.0000\n",
      "\n",
      "Summary for Experiment 7_test_017:\n",
      "Total test lines processed: 40\n"
     ]
    }
   ],
   "source": [
    "# Go through experiment log folders and plot performance for each command\n",
    "\n",
    "# saving place for plots!\n",
    "save_folder = f\"./results/{experiment_name}/\"\n",
    "if os.path.exists(save_folder):\n",
    "    if os.path.isdir(save_folder):\n",
    "        shutil.rmtree(save_folder)\n",
    "    else:\n",
    "        os.remove(save_folder)\n",
    "os.makedirs(save_folder, exist_ok=False)\n",
    "\n",
    "for idx, cmd in enumerate(commands):\n",
    "\n",
    "    ds = command_dict[\"dataset_prefix\"]\n",
    "    try:    \n",
    "        selected_dataset = next(name for name in found_datasets if ds in name)\n",
    "        loader = loaders[selected_dataset]\n",
    "    except StopIteration:\n",
    "        print(f\"No dataset found for {ds}, skipping\")\n",
    "        continue\n",
    "\n",
    "    output_log = f\"{idx}_{cmd['command']}_{cmd['dataset_prefix']}\"\n",
    "    log_dir = os.path.join(\"logs\", experiment_name, output_log)\n",
    "    output_stdout = []\n",
    "    if cmd[\"command\"] == \"train\":\n",
    "        subprocess.run([\n",
    "            \"python\", \"../plot_train_performance.py\",\n",
    "            \"-f\", log_dir,\n",
    "            \"-e\", output_log,\n",
    "            \"--save_folder\", save_folder\n",
    "        ])\n",
    "\n",
    "    elif cmd[\"command\"] == \"test\":\n",
    "        subprocess.run([\n",
    "            \"python\", \"../plot_testing_performance.py\",\n",
    "            \"-f\", log_dir,\n",
    "            \"-e\", output_log,\n",
    "            \"--save_folder\", save_folder\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "129cc924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PoC classifier loading from a location\n",
    "classifier_loaded = SKLearnClassifierWrapper(classifier=None).load_classifier(path = f\"models/{experiment_name}\",name = \"model_lin_SGD.bin\")\n",
    "\n",
    "#PoC loading preprocessing\n",
    "preprocessor_loaded = PreprocessingWrapper(experiment_name=experiment_name).load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slips-ml-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
