{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e9265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # \".\" = current folder (pipeline_ml_training)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pipeline_ml_training.dataset_wrapper import find_and_load_datasets\n",
    "from pipeline_ml_training.classifier_wrapper import SKLearnClassifierWrapper\n",
    "from pipeline_ml_training.preprocessing_wrapper import PreprocessingWrapper\n",
    "from pipeline_ml_training.logger import Logger\n",
    "from pipeline_ml_training.features import FeatureExtraction\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning,module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a20e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths, constants\n",
    "root = \"../../../dataset-private/\" # path to the datasets \n",
    "validation_split=0.1\n",
    "experiment_name = \"test_plotting\"\n",
    "seed = 1111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a11bd2b",
   "metadata": {},
   "source": [
    "## Loading, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa3055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found datasets: ['001-zeek-scenario-malicious', '003-zeek-scenario-malicious', '008-zeek-mixed', '009-zeek-malicious', '010-zeek-mixed', '011-zeek-mixed', '012-zeek-mixed', '013-zeek-mixed', '014-zeek-malicious', '015-zeek-malicious', '016-zeek-malicious', '017-zeek-malicious', '018-zeek-malicious', '020-zeek-malicious', '021-zeek-malicious', '022-zeek-malicious', '023-zeek-malicious', '024-zeek-malicious', '025-zeek-malicious', '026-zeek-malicious', '027-zeek-malicious', '028-zeek-malicious', '029-zeek-malicious', '030-zeek-malicious', '031-zeek-malicious', '032-zeek-malicious', '033-zeek-malicious', '034-zeek-malicious', '035-zeek-malicious', '036-zeek-malicious', '037-zeek-mixed']\n",
      "001-zeek-scenario-malicious: 253 samples\n",
      "003-zeek-scenario-malicious: 361 samples\n",
      "008-zeek-mixed: 5603 samples\n",
      "009-zeek-malicious: 79401 samples\n",
      "010-zeek-mixed: 5310 samples\n",
      "011-zeek-mixed: 8722 samples\n",
      "012-zeek-mixed: 3810 samples\n",
      "013-zeek-mixed: 26241 samples\n",
      "014-zeek-malicious: 26738 samples\n",
      "015-zeek-malicious: 197722 samples\n",
      "016-zeek-malicious: 34633 samples\n",
      "017-zeek-malicious: 39381 samples\n",
      "018-zeek-malicious: 33986 samples\n",
      "020-zeek-malicious: 35159 samples\n",
      "021-zeek-malicious: 33878 samples\n",
      "022-zeek-malicious: 5533 samples\n",
      "023-zeek-malicious: 5460 samples\n",
      "024-zeek-malicious: 5533 samples\n",
      "025-zeek-malicious: 5341 samples\n",
      "026-zeek-malicious: 5355 samples\n",
      "027-zeek-malicious: 2217 samples\n",
      "028-zeek-malicious: 2136 samples\n",
      "029-zeek-malicious: 2447 samples\n",
      "030-zeek-malicious: 2238 samples\n",
      "031-zeek-malicious: 2196 samples\n",
      "032-zeek-malicious: 26738 samples\n",
      "033-zeek-malicious: 11611 samples\n",
      "034-zeek-malicious: 11679 samples\n",
      "035-zeek-malicious: 11853 samples\n",
      "036-zeek-malicious: 11797 samples\n",
      "037-zeek-mixed: 5850 samples\n"
     ]
    }
   ],
   "source": [
    "loaders = find_and_load_datasets(root) #helper function from dataset_loader.py\n",
    "\n",
    "found_datasets=list(loaders.keys())\n",
    "print(\"Found datasets:\", found_datasets)\n",
    "\n",
    "\"\"\" results = sample_n_from_each_dataset(loaders,n=3)\n",
    "for ds_name, info in results.items():\n",
    "    print(f\"Dataset: {ds_name}  (file used: {info['file']})  samples: {len(info['samples'])}\")\n",
    "    display(info['df']) \"\"\"\n",
    "\n",
    "#print datasets\n",
    "for name, loader in loaders.items():\n",
    "    print(f\"{name}: {len(loader)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b58f1",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466cc851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tree_Hoeff = tree.HoeffdingAdaptiveTreeClassifier(seed=seed,max_size=10,max_depth=15)\\nmodel = ensemble.ADWINBoostingClassifier(seed=seed,model = tree_Hoeff,n_models=5)\\n\\n\\n# model = forest.ARFClassifier(seed=seed,n_models=50, max_size=10, warning_detector=drift.ADWIN(delta=0.05))\\n\\n\\n# final wapper for pipeline\\nclassifier = RiverClassifierWrapper(model,preprocessing_handler=preprocessor)\\n '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature processing\n",
    "feature_extraction = FeatureExtraction()\n",
    "\n",
    "#preprocessing\n",
    "scaler = StandardScaler() \n",
    "preprocessor = PreprocessingWrapper(experiment_name=experiment_name)\n",
    "preprocessor.add_step(\"scaler\", scaler)\n",
    "\n",
    "\"\"\" pca = IncrementalPCA(n_components=7)\n",
    "preprocessor.add_step(\"pca\", pca) \"\"\"\n",
    "\n",
    "# other steps here? add your own!\n",
    "\n",
    "#classifiers:\n",
    "# sklearn SGD linear\n",
    "model = SGDClassifier(loss='hinge', penalty='l2',random_state=seed) \n",
    "classifier = SKLearnClassifierWrapper(model,preprocessing_handler=preprocessor)\n",
    "\n",
    "\n",
    "\"\"\" tree_Hoeff = tree.HoeffdingAdaptiveTreeClassifier(seed=seed,max_size=10,max_depth=15)\n",
    "model = ensemble.ADWINBoostingClassifier(seed=seed,model = tree_Hoeff,n_models=5)\n",
    "\n",
    "\n",
    "# model = forest.ARFClassifier(seed=seed,n_models=50, max_size=10, warning_detector=drift.ADWIN(delta=0.05))\n",
    "\n",
    "\n",
    "# final wapper for pipeline\n",
    "classifier = RiverClassifierWrapper(model,preprocessing_handler=preprocessor)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adae8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of commands to run\n",
    "# each command is either \"train\" or \"test\"\n",
    "# dataset_prefix is 3 numbers always - which dataset to use (008, 009, 010, ...)\n",
    "# validation = use validation portion when training\n",
    "\n",
    "commands = [\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"008\", \"validation\": True},\n",
    "\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11037f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not fitted.\n",
      "Training on dataset 008-zeek-mixed\n",
      "Processing batch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5\n"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "    # call batch from dataset\n",
    "    # process features\n",
    "    # preprocessing (scaling)\n",
    "    # train on model with validation, logger for metrics!\n",
    "    # save model after the whole dataset is done\n",
    "    # reporting, metrics, plots, etc.\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "# Ensure log experiment folder exists\n",
    "experiment_folder = os.path.join(\".\", \"logs\", experiment_name)\n",
    "if os.path.exists(experiment_folder):\n",
    "    if os.path.isdir(experiment_folder):\n",
    "        shutil.rmtree(experiment_folder)\n",
    "    else:\n",
    "        os.remove(experiment_folder)\n",
    "os.makedirs(experiment_folder, exist_ok=False)\n",
    "\n",
    "# Save config to configs.txt in the experiment folder (for reproducibility)\n",
    "config_path = os.path.join(experiment_folder, \"configs.txt\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"seed\": seed,\n",
    "        \"validation_split\": validation_split,\n",
    "        \"commands\": commands,\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"root\": root\n",
    "    }, f, indent=4)\n",
    "\n",
    "# check if the model is fitted (now just to know if we can test from the start or need to train first)\n",
    "try:\n",
    "    dummy_input = np.zeros((1, model.n_features_in_))\n",
    "    classifier.predict(dummy_input)\n",
    "    is_fitted = True\n",
    "except Exception:\n",
    "    print(\"Model is not fitted.\")\n",
    "    is_fitted = False\n",
    "\n",
    "\n",
    "# main loop doing commands one by one, and storing logs\n",
    "for command_idx,command_dict in enumerate(commands):\n",
    "\n",
    "    #find the dataset we wanted to use\n",
    "    ds = command_dict[\"dataset_prefix\"]\n",
    "    try:    \n",
    "        selected_dataset = next(name for name in found_datasets if ds in name)\n",
    "        loader = loaders[selected_dataset]\n",
    "    except StopIteration:\n",
    "        print(f\"No dataset found for {ds}, skipping\")\n",
    "        if command_idx == 0 and not is_fitted:\n",
    "            print(\"No dataset for the first training command, exiting\")\n",
    "            exit(1)\n",
    "        continue\n",
    "\n",
    "    # based on the command specified, do the action train/test\n",
    "    command = command_dict[\"command\"]\n",
    "    num_batches = command_dict.get(\"batches\", None)\n",
    "    training_batches = loader.batches()\n",
    "    if num_batches is not None:\n",
    "        training_batches = min(num_batches, loader.batches())\n",
    "\n",
    "    if command == \"train\":\n",
    "        loader.reset_epoch(batch_size=500)\n",
    "        path_to_logfile = f\"{command_idx}_train_{ds}\"\n",
    "        logger = Logger(experiment_name = f\"{experiment_name}\", path_to_logfile = path_to_logfile, overwrite=True)\n",
    "        print(f\"Training on dataset {selected_dataset}\")\n",
    "        do_validation = command_dict.get(\"validation\", False)\n",
    "\n",
    "        for i in range(training_batches):\n",
    "            if i %5 == 0:\n",
    "                print(f\"Processing batch {i}\")\n",
    "\n",
    "\n",
    "            batch = loader.next_batch()\n",
    "            X, y = feature_extraction.process_batch(batch)\n",
    "\n",
    "            sum_labeled_flows = len(y)\n",
    "            if do_validation:\n",
    "                try:\n",
    "\n",
    "                    validation_indices = rng.choice(\n",
    "                        X.shape[0],\n",
    "                        size=int(validation_split * X.shape[0]),\n",
    "                        replace=False,\n",
    "                    )\n",
    "                    train_indices = np.array(  # the rest is validation\n",
    "                        sorted(\n",
    "                            set(range(X.shape[0])) - set(validation_indices)\n",
    "                        )\n",
    "                    )\n",
    "                    X_train, X_val, y_gt_train, y_gt_val = X.iloc[train_indices], X.iloc[validation_indices], y.iloc[train_indices], y.iloc[validation_indices]\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during train_test_split: {e}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "                #preprocessor\n",
    "                preprocessor.partial_fit(X_train)\n",
    "                X_train_processed = preprocessor.transform(X_train)\n",
    "\n",
    "                #classif\n",
    "                classifier.partial_fit(X_train_processed, y_gt_train)\n",
    "                y_pred_train = classifier.predict(X_train_processed)\n",
    "\n",
    "                # predict on validation set\n",
    "                if X_val.shape[0] == 0:\n",
    "                    y_pred_val = np.array([])\n",
    "                else:\n",
    "                    X_val_processed = preprocessor.transform(X_val)\n",
    "                    y_pred_val = classifier.predict(X_val_processed)\n",
    "\n",
    "                logger.save_training_results(\n",
    "                    y_pred_train, y_gt_train, y_pred_val, y_gt_val, sum_labeled_flows\n",
    "                )\n",
    "            else:\n",
    "                preprocessor.partial_fit(X)\n",
    "                X_processed = preprocessor.transform(X)\n",
    "                classifier.partial_fit(X_processed, y)\n",
    "                y_pred_train = classifier.predict(X_processed)\n",
    "                logger.save_training_results(\n",
    "                    y_pred_train, y, None, None, sum_labeled_flows # None is for validation\n",
    "                )\n",
    "\n",
    "        # After training, plot the training performance using the external script, not here!\n",
    "\n",
    "\n",
    "    elif command == \"test\":\n",
    "        path_to_logfile = f\"{command_idx}_test_{ds}\"\n",
    "        logger = Logger(experiment_name = f\"{experiment_name}\",path_to_logfile = path_to_logfile, overwrite=True)\n",
    "        loader.reset_epoch(batch_size=1_000)\n",
    "        print(f\"Testing on dataset {selected_dataset}\")\n",
    "        for i in range(loader.batches()):\n",
    "            batch = loader.next_batch()\n",
    "            if i %25 == 0:\n",
    "                print(f\"Processing batch {i}\")\n",
    "            X, y = feature_extraction.process_batch(batch)\n",
    "            if X.shape[0] == 0:\n",
    "                continue\n",
    "            X_processed = preprocessor.transform(X)\n",
    "            y_pred = classifier.predict(X_processed)\n",
    "            logger.save_test_results(y, y_pred)\n",
    "    else:\n",
    "        print(f\"Unknown command {command}, skipping\")\n",
    "        continue\n",
    "\n",
    "#save model, preprocessor steps and add config to the configs.txt\n",
    "models_path= f\"./models/{experiment_name}\"\n",
    "# ensure models directory is fresh (delete if already created)\n",
    "models_path = f\"./models/{experiment_name}\"\n",
    "if os.path.exists(models_path):\n",
    "    if os.path.isdir(models_path):\n",
    "        shutil.rmtree(models_path)\n",
    "    else:\n",
    "        os.remove(models_path)\n",
    "os.makedirs(models_path, exist_ok=False)\n",
    "classifier.save_classifier(path = models_path ,name = \"model_lin_SGD.bin\")\n",
    "preprocessor.save() #saves in models/<experiment_name>/preprocessing/<step_name>\n",
    "\n",
    "#  append feature names from the first preprocessing step and model parameters to configs.txt\n",
    "# get feature names from the first step in the preprocessor\n",
    "first_preprocessor_step = preprocessor.steps[0][1]\n",
    "if hasattr(first_preprocessor_step, 'get_feature_names_out'):\n",
    "    feature_names = first_preprocessor_step.get_feature_names_out()\n",
    "elif hasattr(first_preprocessor_step, 'feature_names_in_'):\n",
    "    feature_names = first_preprocessor_step.feature_names_in_\n",
    "else:\n",
    "    feature_names = None\n",
    "\n",
    "# Get model parameters\n",
    "if hasattr(model, \"get_params\"):\n",
    "    model_params = model.get_params()\n",
    "else:\n",
    "    model_params = None\n",
    "model_info = {\n",
    "    \"class\": type(model).__name__,\n",
    "    \"loss\": getattr(model, \"loss\", None),\n",
    "    \"params\": model_params\n",
    "}\n",
    "\n",
    "# Append to configs.txt\n",
    "with open(config_path, \"a\") as f:\n",
    "    f.write(\"\\n\\n# Feature names from first preprocessing step:\\n\")\n",
    "    if feature_names is not None:\n",
    "        f.write(json.dumps({\"feature_names\": list(feature_names)}, indent=4))\n",
    "    else:\n",
    "        f.write(\"# Feature names not available\\n\")\n",
    "    f.write(\"\\n\\n# Model information:\\n\")\n",
    "    f.write(json.dumps(model_info, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e18a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(classifier.classifier, 'n_warnings_detected'):\n",
    "    print(classifier.classifier.n_warnings_detected())\n",
    "\n",
    "if hasattr(classifier.classifier, 'n_drifts_detected'):\n",
    "    print(classifier.classifier.n_drifts_detected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379b121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading logfile: logs/test_plotting/0_train_008\n",
      "[INFO] Accumulating batch and cumulative metrics...\n",
      "Validation plots will be saved to: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_plotting/training/0_train_008/validation\n",
      "Training plots will be saved to: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_plotting/training/0_train_008/training\n",
      "Comparison plots will be saved to: /home/svobojan/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/test_plotting/training/0_train_008/comparison\n",
      "[INFO] Not enough batches for last-10 (validation), skipping.\n",
      "[INFO] Not enough batches for last-20 (validation), skipping.\n",
      "[INFO] Not enough batches for last-10 (training), skipping.\n",
      "[INFO] Not enough batches for last-20 (training), skipping.\n",
      "\n",
      "=== VALIDATION Multi-class (Aggregated) ===\n",
      "Accuracy:             0.9729\n",
      "Malware F1:           0.9819\n",
      "Malware FPR:          0.0411\n",
      "Malware FNR:          0.0225\n",
      "Macro F1:             0.9639\n",
      "Precision:            0.9864\n",
      "Recall:               0.9775\n",
      "MCC:                  0.9280\n",
      "\n",
      "=== TRAINING Multi-class (Aggregated) ===\n",
      "Accuracy:             0.9778\n",
      "Malware F1:           0.9858\n",
      "Malware FPR:          0.0559\n",
      "Malware FNR:          0.0128\n",
      "Macro F1:             0.9673\n",
      "Precision:            0.9844\n",
      "Recall:               0.9872\n",
      "MCC:                  0.9347\n",
      "\n",
      "=== Per-class metrics (Aggregated) - VALIDATION ===\n",
      "Class                 TP       TN       FP       FN      Acc     Prec      Rec       F1\n",
      "Benign                70      217        5        3   0.9729   0.9333   0.9589   0.9459\n",
      "Malicious            217       70        3        5   0.9729   0.9864   0.9775   0.9819\n",
      "\n",
      "=== Per-class metrics (Aggregated) - TRAINING ===\n",
      "Class                 TP       TN       FP       FN      Acc     Prec      Rec       F1\n",
      "Benign               557     2080       27       33   0.9778   0.9538   0.9441   0.9489\n",
      "Malicious           2080      557       33       27   0.9778   0.9844   0.9872   0.9858\n",
      "\n",
      "Summary for Experiment 0_train_008:\n",
      "Total batches processed: 6\n",
      "Data type: Training/Validation split\n"
     ]
    }
   ],
   "source": [
    "# Go through experiment log folders and plot performance for each command\n",
    "\n",
    "# saving place for plots!\n",
    "save_folder = f\"./results/{experiment_name}/\"\n",
    "if os.path.exists(save_folder):\n",
    "    if os.path.isdir(save_folder):\n",
    "        shutil.rmtree(save_folder)\n",
    "    else:\n",
    "        os.remove(save_folder)\n",
    "os.makedirs(save_folder, exist_ok=False)\n",
    "\n",
    "for idx, cmd in enumerate(commands):\n",
    "\n",
    "    ds = command_dict[\"dataset_prefix\"]\n",
    "    try:    \n",
    "        selected_dataset = next(name for name in found_datasets if ds in name)\n",
    "        loader = loaders[selected_dataset]\n",
    "    except StopIteration:\n",
    "        print(f\"No dataset found for {ds}, skipping\")\n",
    "        continue\n",
    "\n",
    "    output_log = f\"{idx}_{cmd['command']}_{cmd['dataset_prefix']}\"\n",
    "    log_dir = os.path.join(\"logs\", experiment_name, output_log)\n",
    "    output_stdout = []\n",
    "    if cmd[\"command\"] == \"train\":\n",
    "        subprocess.run([\n",
    "            \"python\", \"../plot_train_performance.py\",\n",
    "            \"-f\", log_dir,\n",
    "            \"-e\", output_log,\n",
    "            \"--save_folder\", save_folder\n",
    "        ])\n",
    "\n",
    "    elif cmd[\"command\"] == \"test\":\n",
    "        subprocess.run([\n",
    "            \"python\", \"../plot_testing_performance.py\",\n",
    "            \"-f\", log_dir,\n",
    "            \"-e\", output_log,\n",
    "            \"--save_folder\", save_folder\n",
    "        ])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slips-ml-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
