{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e9265f",
   "metadata": {},
   "outputs": [],
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))  # \".\" = current folder (pipeline_ml_training)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import subprocess\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning,module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a20e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths, constants\n",
    "root = \"/opt/Datasets/security-datasets-for-testing/\" # path to the datasets \n",
    "validation_split=0.1\n",
    "experiment_name = \"river_adwin_boosting_classifier_only_on_10_\"\n",
    "seed = 1111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a11bd2b",
   "metadata": {},
   "source": [
    "## Loading, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa3055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found datasets: ['001-zeek-scenario-malicious', '002-zeek-scenario-port-scanning', '003-zeek-scenario-malicious', '005-zeek-scenario-malicious', '006-zeek-scenario-ssh', '007-zeek-scenario-ssh-infected', '008-zeek-mixed', '009-zeek-malicious', '010-zeek-mixed', '011-zeek-mixed', '012-zeek-mixed', '013-zeek-mixed', '014-zeek-malicious', '015-zeek-malicious', '016-zeek-malicious', '017-zeek-malicious', '018-zeek-malicious', '020-zeek-malicious', '021-zeek-malicious', '022-zeek-malicious', '023-zeek-malicious', '024-zeek-malicious', '025-zeek-malicious', '026-zeek-malicious', '027-zeek-malicious', '028-zeek-malicious', '029-zeek-malicious', '030-zeek-malicious', '031-zeek-malicious', '032-zeek-malicious', '033-zeek-malicious', '034-zeek-malicious', '035-zeek-malicious', '036-zeek-malicious', '037-zeek-mixed']\n",
      "001-zeek-scenario-malicious: 253 samples\n",
      "002-zeek-scenario-port-scanning: 4504 samples\n",
      "003-zeek-scenario-malicious: 361 samples\n",
      "005-zeek-scenario-malicious: 992 samples\n",
      "006-zeek-scenario-ssh: 18 samples\n",
      "007-zeek-scenario-ssh-infected: 36415 samples\n",
      "008-zeek-mixed: 5603 samples\n",
      "009-zeek-malicious: 79401 samples\n",
      "010-zeek-mixed: 5310 samples\n",
      "011-zeek-mixed: 8722 samples\n",
      "012-zeek-mixed: 3810 samples\n",
      "013-zeek-mixed: 26241 samples\n",
      "014-zeek-malicious: 26738 samples\n",
      "015-zeek-malicious: 197722 samples\n",
      "016-zeek-malicious: 34633 samples\n",
      "017-zeek-malicious: 39381 samples\n",
      "018-zeek-malicious: 33986 samples\n",
      "020-zeek-malicious: 35159 samples\n",
      "021-zeek-malicious: 33878 samples\n",
      "022-zeek-malicious: 5533 samples\n",
      "023-zeek-malicious: 5460 samples\n",
      "024-zeek-malicious: 5533 samples\n",
      "025-zeek-malicious: 5341 samples\n",
      "026-zeek-malicious: 5355 samples\n",
      "027-zeek-malicious: 2217 samples\n",
      "028-zeek-malicious: 2136 samples\n",
      "029-zeek-malicious: 2447 samples\n",
      "030-zeek-malicious: 2238 samples\n",
      "031-zeek-malicious: 2196 samples\n",
      "032-zeek-malicious: 26738 samples\n",
      "033-zeek-malicious: 11611 samples\n",
      "034-zeek-malicious: 11679 samples\n",
      "035-zeek-malicious: 11853 samples\n",
      "036-zeek-malicious: 11797 samples\n",
      "037-zeek-mixed: 5850 samples\n"
     ]
    }
   ],
   "source": [
    "loaders = find_and_load_datasets(root) #helper function from dataset_loader.py\n",
    "\n",
    "found_datasets=list(loaders.keys())\n",
    "print(\"Found datasets:\", found_datasets)\n",
    "\n",
    "\"\"\" results = sample_n_from_each_dataset(loaders,n=3)\n",
    "for ds_name, info in results.items():\n",
    "    print(f\"Dataset: {ds_name}  (file used: {info['file']})  samples: {len(info['samples'])}\")\n",
    "    display(info['df']) \"\"\"\n",
    "\n",
    "#print datasets\n",
    "for name, loader in loaders.items():\n",
    "    print(f\"{name}: {len(loader)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3b58f1",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "466cc851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tree_Hoeff = tree.HoeffdingAdaptiveTreeClassifier(seed=seed,max_size=10,max_depth=15)\\nmodel = ensemble.ADWINBoostingClassifier(seed=seed,model = tree_Hoeff,n_models=5)\\n\\n\\n# model = forest.ARFClassifier(seed=seed,n_models=50, max_size=10, warning_detector=drift.ADWIN(delta=0.05))\\n\\n\\n# final wapper for pipeline\\nclassifier = RiverClassifierWrapper(model,preprocessing_handler=preprocessor)\\n '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature processing\n",
    "feature_extraction = FeatureExtraction()\n",
    "\n",
    "#preprocessing\n",
    "scaler = StandardScaler() \n",
    "preprocessor = PreprocessingWrapper(experiment_name=experiment_name)\n",
    "preprocessor.add_step(\"scaler\", scaler)\n",
    "\n",
    "\"\"\" pca = IncrementalPCA(n_components=7)\n",
    "preprocessor.add_step(\"pca\", pca) \"\"\"\n",
    "\n",
    "# other steps here? add your own!\n",
    "\n",
    "#classifiers:\n",
    "# sklearn SGD linear\n",
    "model = SGDClassifier(loss='hinge', penalty='l2',random_state=seed) \n",
    "classifier = SKLearnClassifierWrapper(model,preprocessing_handler=preprocessor)\n",
    "\n",
    "\n",
    "\"\"\" tree_Hoeff = tree.HoeffdingAdaptiveTreeClassifier(seed=seed,max_size=10,max_depth=15)\n",
    "model = ensemble.ADWINBoostingClassifier(seed=seed,model = tree_Hoeff,n_models=5)\n",
    "\n",
    "\n",
    "# model = forest.ARFClassifier(seed=seed,n_models=50, max_size=10, warning_detector=drift.ADWIN(delta=0.05))\n",
    "\n",
    "\n",
    "# final wapper for pipeline\n",
    "classifier = RiverClassifierWrapper(model,preprocessing_handler=preprocessor)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adae8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of commands to run\n",
    "# each command is either \"train\" or \"test\"\n",
    "# dataset_prefix is 3 numbers always - which dataset to use (008, 009, 010, ...)\n",
    "# validation = use validation portion when training\n",
    "\n",
    "commands = [\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"001\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"008\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"009\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"010\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"011\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"012\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"013\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"014\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"015\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"016\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"017\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"022\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"023\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"024\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"027\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"028\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"029\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"032\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"033\", \"validation\": True},\n",
    "    {\"command\": \"train\", \"dataset_prefix\": \"034\", \"validation\": True},\n",
    "    \n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"001\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"008\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"009\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"010\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"011\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"012\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"013\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"014\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"015\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"016\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"017\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"018\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"020\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"021\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"025\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"026\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"030\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"031\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"035\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"036\"},\n",
    "    {\"command\":\"test\", \"dataset_prefix\":\"037\"}\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11037f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not fitted.\n",
      "Training on dataset 008-zeek-mixed\n",
      "Processing batch 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 5\n"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "    # call batch from dataset\n",
    "    # process features\n",
    "    # preprocessing (scaling)\n",
    "    # train on model with validation, logger for metrics!\n",
    "    # save model after the whole dataset is done\n",
    "    # reporting, metrics, plots, etc.\n",
    "\n",
    "rng = np.random.default_rng(seed)\n",
    "\n",
    "# Ensure log experiment folder exists\n",
    "experiment_folder = os.path.join(\".\", \"logs\", experiment_name)\n",
    "if os.path.exists(experiment_folder):\n",
    "    if os.path.isdir(experiment_folder):\n",
    "        shutil.rmtree(experiment_folder)\n",
    "    else:\n",
    "        os.remove(experiment_folder)\n",
    "os.makedirs(experiment_folder, exist_ok=False)\n",
    "\n",
    "# Save config to configs.txt in the experiment folder (for reproducibility)\n",
    "config_path = os.path.join(experiment_folder, \"configs.txt\")\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"seed\": seed,\n",
    "        \"validation_split\": validation_split,\n",
    "        \"commands\": commands,\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"root\": root\n",
    "    }, f, indent=4)\n",
    "\n",
    "# check if the model is fitted (now just to know if we can test from the start or need to train first)\n",
    "try:\n",
    "    dummy_input = np.zeros((1, model.n_features_in_))\n",
    "    classifier.predict(dummy_input)\n",
    "    is_fitted = True\n",
    "except Exception:\n",
    "    print(\"Model is not fitted.\")\n",
    "    is_fitted = False\n",
    "\n",
    "\n",
    "# main loop doing commands one by one, and storing logs\n",
    "for command_idx,command_dict in enumerate(commands):\n",
    "\n",
    "    #find the dataset we wanted to use\n",
    "    ds = command_dict[\"dataset_prefix\"]\n",
    "    try:    \n",
    "        selected_dataset = next(name for name in found_datasets if ds in name)\n",
    "        loader = loaders[selected_dataset]\n",
    "    except StopIteration:\n",
    "        print(f\"No dataset found for {ds}, skipping\")\n",
    "        if command_idx == 0 and not is_fitted:\n",
    "            print(\"No dataset for the first training command, exiting\")\n",
    "            exit(1)\n",
    "        continue\n",
    "\n",
    "    # based on the command specified, do the action train/test\n",
    "    command = command_dict[\"command\"]\n",
    "    num_batches = command_dict.get(\"batches\", None)\n",
    "    training_batches = loader.batches()\n",
    "    if num_batches is not None:\n",
    "        training_batches = min(num_batches, loader.batches())\n",
    "\n",
    "    if command == \"train\":\n",
    "        loader.reset_epoch(batch_size=500)\n",
    "        path_to_logfile = f\"{command_idx}_train_{ds}\"\n",
    "        logger = Logger(experiment_name = f\"{experiment_name}\", path_to_logfile = path_to_logfile, overwrite=True)\n",
    "        print(f\"Training on dataset {selected_dataset}\")\n",
    "        do_validation = command_dict.get(\"validation\", False)\n",
    "\n",
    "        for i in range(training_batches):\n",
    "            if i %5 == 0:\n",
    "                print(f\"Processing batch {i}\")\n",
    "\n",
    "\n",
    "            batch = loader.next_batch()\n",
    "            X, y = feature_extraction.process_batch(batch)\n",
    "\n",
    "            # skip empty batches (no rows or no columns)\n",
    "            if X is None or getattr(X, \"shape\", (0, 0))[0] == 0 or getattr(X, \"shape\", (0, 0))[1] == 0:\n",
    "                continue\n",
    "\n",
    "            sum_labeled_flows = len(y)\n",
    "            if do_validation:\n",
    "                try:\n",
    "                    val_size = int(validation_split * X.shape[0])\n",
    "                    if val_size <= 0 or val_size >= X.shape[0]:\n",
    "                        # not enough data to split; fall back to training on full batch without validation\n",
    "                        preprocessor.partial_fit(X)\n",
    "                        X_processed = preprocessor.transform(X)\n",
    "                        classifier.partial_fit(X_processed, y)\n",
    "                        y_pred_train = classifier.predict(X_processed)\n",
    "                        logger.save_training_results(\n",
    "                            y_pred_train, y, None, None, sum_labeled_flows\n",
    "                        )\n",
    "                        continue\n",
    "\n",
    "                    validation_indices = rng.choice(\n",
    "                        X.shape[0],\n",
    "                        size=val_size,\n",
    "                        replace=False,\n",
    "                    )\n",
    "                    train_indices = np.array(\n",
    "                        sorted(\n",
    "                            set(range(X.shape[0])) - set(validation_indices)\n",
    "                        )\n",
    "                    )\n",
    "                    if train_indices.size == 0:\n",
    "                        continue\n",
    "                    X_train, X_val = X.iloc[train_indices], X.iloc[validation_indices]\n",
    "                    y_gt_train, y_gt_val = y.iloc[train_indices], y.iloc[validation_indices]\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during train_test_split: {e}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "                if X_train.shape[0] == 0 or X_train.shape[1] == 0:\n",
    "                    continue\n",
    "\n",
    "                #preprocessor\n",
    "                preprocessor.partial_fit(X_train)\n",
    "                X_train_processed = preprocessor.transform(X_train)\n",
    "\n",
    "                #classif\n",
    "                classifier.partial_fit(X_train_processed, y_gt_train)\n",
    "                y_pred_train = classifier.predict(X_train_processed)\n",
    "\n",
    "                # predict on validation set\n",
    "                if X_val.shape[0] == 0 or X_val.shape[1] == 0:\n",
    "                    y_pred_val = np.array([])\n",
    "                else:\n",
    "                    X_val_processed = preprocessor.transform(X_val)\n",
    "                    y_pred_val = classifier.predict(X_val_processed)\n",
    "\n",
    "                logger.save_training_results(\n",
    "                    y_pred_train, y_gt_train, y_pred_val, y_gt_val, sum_labeled_flows\n",
    "                )\n",
    "            else:\n",
    "                preprocessor.partial_fit(X)\n",
    "                X_processed = preprocessor.transform(X)\n",
    "                classifier.partial_fit(X_processed, y)\n",
    "                y_pred_train = classifier.predict(X_processed)\n",
    "                logger.save_training_results(\n",
    "                    y_pred_train, y, None, None, sum_labeled_flows # None is for validation\n",
    "                )\n",
    "\n",
    "        # After training, plot the training performance using the external script, not here!\n",
    "\n",
    "\n",
    "    elif command == \"test\":\n",
    "        path_to_logfile = f\"{command_idx}_test_{ds}\"\n",
    "        logger = Logger(experiment_name = f\"{experiment_name}\",path_to_logfile = path_to_logfile, overwrite=True)\n",
    "        loader.reset_epoch(batch_size=1_000)\n",
    "        print(f\"Testing on dataset {selected_dataset}\")\n",
    "        for i in range(loader.batches()):\n",
    "            batch = loader.next_batch()\n",
    "            if i %25 == 0:\n",
    "                print(f\"Processing batch {i}\")\n",
    "            X, y = feature_extraction.process_batch(batch)\n",
    "            if X.shape[0] == 0:\n",
    "                continue\n",
    "            X_processed = preprocessor.transform(X)\n",
    "            y_pred = classifier.predict(X_processed)\n",
    "            logger.save_test_results(y, y_pred)\n",
    "    else:\n",
    "        print(f\"Unknown command {command}, skipping\")\n",
    "        continue\n",
    "\n",
    "#save model, preprocessor steps and add config to the configs.txt\n",
    "models_path= f\"./models/{experiment_name}\"\n",
    "# ensure models directory is fresh (delete if already created)\n",
    "models_path = f\"./models/{experiment_name}\"\n",
    "if os.path.exists(models_path):\n",
    "    if os.path.isdir(models_path):\n",
    "        shutil.rmtree(models_path)\n",
    "    else:\n",
    "        os.remove(models_path)\n",
    "os.makedirs(models_path, exist_ok=False)\n",
    "classifier.save_classifier(path = models_path ,name = \"model_lin_SGD.bin\")\n",
    "preprocessor.save() #saves in models/<experiment_name>/preprocessing/<step_name>\n",
    "\n",
    "#  append feature names from the first preprocessing step and model parameters to configs.txt\n",
    "# get feature names from the first step in the preprocessor\n",
    "first_preprocessor_step = preprocessor.steps[0][1]\n",
    "if hasattr(first_preprocessor_step, 'get_feature_names_out'):\n",
    "    feature_names = first_preprocessor_step.get_feature_names_out()\n",
    "elif hasattr(first_preprocessor_step, 'feature_names_in_'):\n",
    "    feature_names = first_preprocessor_step.feature_names_in_\n",
    "else:\n",
    "    feature_names = None\n",
    "\n",
    "# Get model parameters\n",
    "if hasattr(model, \"get_params\"):\n",
    "    model_params = model.get_params()\n",
    "else:\n",
    "    model_params = None\n",
    "model_info = {\n",
    "    \"class\": type(model).__name__,\n",
    "    \"loss\": getattr(model, \"loss\", None),\n",
    "    \"params\": model_params\n",
    "}\n",
    "\n",
    "# Append to configs.txt\n",
    "with open(config_path, \"a\") as f:\n",
    "    f.write(\"\\n\\n# Feature names from first preprocessing step:\\n\")\n",
    "    if feature_names is not None:\n",
    "        f.write(json.dumps({\"feature_names\": list(feature_names)}, indent=4))\n",
    "    else:\n",
    "        f.write(\"# Feature names not available\\n\")\n",
    "    f.write(\"\\n\\n# Model information:\\n\")\n",
    "    f.write(json.dumps(model_info, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e18a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(classifier.classifier, 'n_warnings_detected'):\n",
    "    print(classifier.classifier.n_warnings_detected())\n",
    "\n",
    "if hasattr(classifier.classifier, 'n_drifts_detected'):\n",
    "    print(classifier.classifier.n_drifts_detected())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "379b121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading logfile: logs/test_plotting/0_train_008\n",
      "[INFO] Accumulating batch and cumulative metrics...\n",
      "Validation plots will be saved to: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/training/0_train_010/validation\n",
      "Training plots will be saved to: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/training/0_train_010/training\n",
      "Comparison plots will be saved to: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/training/0_train_010/comparison\n",
      "[INFO] Not enough batches for last-10 (validation), skipping.\n",
      "[INFO] Not enough batches for last-20 (validation), skipping.\n",
      "[INFO] Not enough batches for last-10 (training), skipping.\n",
      "[INFO] Not enough batches for last-20 (training), skipping.\n",
      "\n",
      "=== VALIDATION Multi-class (Aggregated) ===\n",
      "Accuracy:             0.9729\n",
      "Malware F1:           0.9819\n",
      "Malware FPR:          0.0411\n",
      "Malware FNR:          0.0225\n",
      "Macro F1:             0.9639\n",
      "Precision:            0.9864\n",
      "Recall:               0.9775\n",
      "MCC:                  0.9280\n",
      "\n",
      "=== TRAINING Multi-class (Aggregated) ===\n",
      "Accuracy:             0.9778\n",
      "Malware F1:           0.9858\n",
      "Malware FPR:          0.0559\n",
      "Malware FNR:          0.0128\n",
      "Macro F1:             0.9673\n",
      "Precision:            0.9844\n",
      "Recall:               0.9872\n",
      "MCC:                  0.9347\n",
      "\n",
      "=== Per-class metrics (Aggregated) - VALIDATION ===\n",
      "Class                 TP       TN       FP       FN      Acc     Prec      Rec       F1\n",
      "Benign                70      217        5        3   0.9729   0.9333   0.9589   0.9459\n",
      "Malicious            217       70        3        5   0.9729   0.9864   0.9775   0.9819\n",
      "\n",
      "=== Per-class metrics (Aggregated) - TRAINING ===\n",
      "Class                 TP       TN       FP       FN      Acc     Prec      Rec       F1\n",
      "Benign               557     2080       27       33   0.9778   0.9538   0.9441   0.9489\n",
      "Malicious           2080      557       33       27   0.9778   0.9844   0.9872   0.9858\n",
      "\n",
      "Summary for Experiment 0_train_008:\n",
      "Total batches processed: 6\n",
      "Data type: Training/Validation split\n",
      "[INFO] Output folder: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/testing/1_test_008\n",
      "[INFO] Reading testing logfile: logs/river_adwin_boosting_classifier_only_on_10/1_test_008\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.9737\n",
      "Malware F1:           0.9823\n",
      "Malware FPR:          0.0342\n",
      "Malware FNR:          0.0237\n",
      "Macro F1:             0.9654\n",
      "Precision:            0.9884\n",
      "Recall:               0.9763\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious           4082     1354       48       99   0.9884   0.9763   0.9823\n",
      "Benign              1354     4082       99       48   0.9319   0.9658   0.9485\n",
      "\n",
      "Summary for Experiment 1_test_008:\n",
      "Total test lines processed: 6\n",
      "[INFO] Output folder: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/testing/2_test_009\n",
      "[INFO] Reading testing logfile: logs/river_adwin_boosting_classifier_only_on_10/2_test_009\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.9479\n",
      "Malware F1:           0.9733\n",
      "Malware FPR:          0.9855\n",
      "Malware FNR:          0.0370\n",
      "Macro F1:             0.4910\n",
      "Precision:            0.9837\n",
      "Recall:               0.9630\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious          61724       15     1020     2370   0.9837   0.9630   0.9733\n",
      "Benign                15    61724     2370     1020   0.0063   0.0145   0.0088\n",
      "\n",
      "Summary for Experiment 2_test_009:\n",
      "Total test lines processed: 80\n",
      "[INFO] Output folder: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/testing/3_test_010\n",
      "[INFO] Reading testing logfile: logs/river_adwin_boosting_classifier_only_on_10/3_test_010\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.9720\n",
      "Malware F1:           0.9782\n",
      "Malware FPR:          0.0687\n",
      "Malware FNR:          0.0040\n",
      "Macro F1:             0.9696\n",
      "Precision:            0.9609\n",
      "Recall:               0.9960\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious           3272     1804      133       13   0.9609   0.9960   0.9782\n",
      "Benign              1804     3272       13      133   0.9928   0.9313   0.9611\n",
      "\n",
      "Summary for Experiment 3_test_010:\n",
      "Total test lines processed: 6\n",
      "[INFO] Output folder: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/testing/4_test_011\n",
      "[INFO] Reading testing logfile: logs/river_adwin_boosting_classifier_only_on_10/4_test_011\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.9604\n",
      "Malware F1:           0.9573\n",
      "Malware FPR:          0.0675\n",
      "Malware FNR:          0.0049\n",
      "Macro F1:             0.9602\n",
      "Precision:            0.9223\n",
      "Recall:               0.9951\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious           3824     4447      322       19   0.9223   0.9951   0.9573\n",
      "Benign              4447     3824       19      322   0.9957   0.9325   0.9631\n",
      "\n",
      "Summary for Experiment 4_test_011:\n",
      "Total test lines processed: 9\n",
      "[INFO] Output folder: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/testing/5_test_012\n",
      "[INFO] Reading testing logfile: logs/river_adwin_boosting_classifier_only_on_10/5_test_012\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.9747\n",
      "Malware F1:           0.9839\n",
      "Malware FPR:          0.0614\n",
      "Malware FNR:          0.0157\n",
      "Macro F1:             0.9619\n",
      "Precision:            0.9836\n",
      "Recall:               0.9843\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious           2881      734       48       46   0.9836   0.9843   0.9839\n",
      "Benign               734     2881       46       48   0.9410   0.9386   0.9398\n",
      "\n",
      "Summary for Experiment 5_test_012:\n",
      "Total test lines processed: 4\n",
      "[INFO] Output folder: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/testing/6_test_013\n",
      "[INFO] Reading testing logfile: logs/river_adwin_boosting_classifier_only_on_10/6_test_013\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.3882\n",
      "Malware F1:           0.5387\n",
      "Malware FPR:          0.1198\n",
      "Malware FNR:          0.6297\n",
      "Macro F1:             0.3152\n",
      "Precision:            0.9884\n",
      "Recall:               0.3703\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious           8848      764      104    15047   0.9884   0.3703   0.5387\n",
      "Benign               764     8848    15047      104   0.0483   0.8802   0.0916\n",
      "\n",
      "Summary for Experiment 6_test_013:\n",
      "Total test lines processed: 27\n",
      "[INFO] Output folder: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/testing/7_test_014\n",
      "[INFO] Reading testing logfile: logs/river_adwin_boosting_classifier_only_on_10/7_test_014\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.4933\n",
      "Malware F1:           0.6604\n",
      "Malware FPR:          0.7619\n",
      "Malware FNR:          0.5060\n",
      "Macro F1:             0.3315\n",
      "Precision:            0.9956\n",
      "Recall:               0.4940\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious           7309       10       32     7486   0.9956   0.4940   0.6604\n",
      "Benign                10     7309     7486       32   0.0013   0.2381   0.0027\n",
      "\n",
      "Summary for Experiment 7_test_014:\n",
      "Total test lines processed: 27\n",
      "[INFO] Output folder: /home/sebas/StratosphereLinuxIPS/modules/flowmldetection/pipeline_ml_training/results/river_adwin_boosting_classifier_only_on_10/testing/8_test_015\n",
      "[INFO] Reading testing logfile: logs/river_adwin_boosting_classifier_only_on_10/8_test_015\n",
      "[INFO] Plotting aggregated class counts (TP+FN per class so-far)...\n",
      "[INFO] Plotting malware metrics (FPR, FNR, F1, Benign-Malicious Acc) over snapshots...\n",
      "[INFO] Saving FPR/FNR-only plot...\n",
      "[INFO] Plotting predicted vs seen counts (per-snapshot) for Malicious & Benign...\n",
      "[INFO] Plotting final confusion matrix (final snapshot)...\n",
      "\n",
      "=== Main final metrics (Aggregated so-far) ===\n",
      "Benign-Malicious Acc: 0.9698\n",
      "Malware F1:           0.9847\n",
      "Malware FPR:          1.0000\n",
      "Malware FNR:          0.0146\n",
      "Macro F1:             0.4923\n",
      "Precision:            0.9840\n",
      "Recall:               0.9854\n",
      "\n",
      "=== Per-class metrics (final snapshot) ===\n",
      "Class                 TP       TN       FP       FN     Prec      Rec       F1\n",
      "Malicious         158365        0     2576     2354   0.9840   0.9854   0.9847\n",
      "Benign                 0   158365     2354     2576   0.0000   0.0000   0.0000\n",
      "\n",
      "Summary for Experiment 8_test_015:\n",
      "Total test lines processed: 198\n"
     ]
    }
   ],
   "source": [
    "# Go through experiment log folders and plot performance for each command\n",
    "\n",
    "# saving place for plots!\n",
    "save_folder = f\"./results/{experiment_name}/\"\n",
    "if os.path.exists(save_folder):\n",
    "    if os.path.isdir(save_folder):\n",
    "        shutil.rmtree(save_folder)\n",
    "    else:\n",
    "        os.remove(save_folder)\n",
    "os.makedirs(save_folder, exist_ok=False)\n",
    "\n",
    "for idx, cmd in enumerate(commands):\n",
    "\n",
    "    ds = command_dict[\"dataset_prefix\"]\n",
    "    try:    \n",
    "        selected_dataset = next(name for name in found_datasets if ds in name)\n",
    "        loader = loaders[selected_dataset]\n",
    "    except StopIteration:\n",
    "        print(f\"No dataset found for {ds}, skipping\")\n",
    "        continue\n",
    "\n",
    "    output_log = f\"{idx}_{cmd['command']}_{cmd['dataset_prefix']}\"\n",
    "    log_dir = os.path.join(\"logs\", experiment_name, output_log)\n",
    "    output_stdout = []\n",
    "    if cmd[\"command\"] == \"train\":\n",
    "        subprocess.run([\n",
    "            \"python\", \"../plot_train_performance.py\",\n",
    "            \"-f\", log_dir,\n",
    "            \"-e\", output_log,\n",
    "            \"--save_folder\", save_folder\n",
    "        ])\n",
    "\n",
    "    elif cmd[\"command\"] == \"test\":\n",
    "        subprocess.run([\n",
    "            \"python\", \"../plot_testing_performance.py\",\n",
    "            \"-f\", log_dir,\n",
    "            \"-e\", output_log,\n",
    "            \"--save_folder\", save_folder\n",
    "        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230941cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
