experiment_name: "example_full_run"
root: "../../../dataset-private/"
seed: 2025
validation_split: 0.1
batch_size_train: 500
batch_size_test: 1000

paths:
  # single experiment directory: runner will create subfolders under this
  experiment_dir: "./experiments"
  # name for preprocessing folder under each command folder
  preprocessing_dir_name: "preprocessing"

dataset_loader:
  batch_size: 1000
  data_subdir: "data"
  prefix_regex: "^\\d{3}"
  persist_cache_threshold: 30000
  # optional: where dataset cache files are stored (will be resolved)
  cache_dir: "./pipeline_ml_training/cache"
  labeled_filenames:
    - "conn.log.labeled"
    - "labeled-conn.log"
    - "conn.log"
  file_encoding: "utf-8"
  file_errors: "ignore"
  shuffle_per_epoch: false

features:
  default_label: "Benign"
  protocols_to_discard:
    - "arp"
    - "icmp"
    - "ipv6-icmp"
  columns_to_discard: []
  column_types:
    dur: "float"
    proto: "float"

preprocessing:
  # steps are (name, type, params)
  # runner will instantiate these via factory mapping (type -> class)
  steps:
    - name: "scaler"
      type: "StandardScaler"
      params: {}
    - name: "pca"
      type: "IncrementalPCA"
      params:
        n_components: 7
  save_steps: true
  step_filename_template: "{name}.bin"

model:
  wrapper: "SKLearnClassifierWrapper"
  classifier_type: "SGDClassifier"
  classifier_params:
    loss: "hinge"
    penalty: "l2"
    random_state: 2025
  save_name: "classifier.bin"
  classes: []        # optional: list class labels if desired
  dummy_flows: {}    # optional: override default dummy flows

commands:
  - name: "train_seq_then_random"
    command: "train"
    batch_size: 400                # per-command override
    validation_split: 0.05         # command-level override
    mixer:
      type: "sequence"
      datasets: ["001", "002", "003"]
      per_dataset_batch_size: 200

  - name: "train_random_balanced"
    command: "train"
    batch_size: 500
    mixer:
      type: "random_batches"
      datasets: ["008", "009", "010"]
      balanced: true
      validation_split: 0.1

  - name: "train_balanced_labels"
    command: "train"
    batch_size: 500
    mixer:
      type: "balanced_by_label"
      datasets: ["009", "015", "016"]
      micro_batch: 32
      # optional explicit label list:
      # labels: ["BENIGN", "MALICIOUS"]
      validation_split: 0.1

  - name: "test_all"
    command: "test"
    batch_size: 1000
    mixer:
      type: "sequence"
      datasets: ["001", "002", "003", "008", "009", "015", "016"]
